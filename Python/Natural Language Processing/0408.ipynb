{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"0408.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"n9QeCJbGeLFo"},"source":["# https://clay-atlas.com/blog/2019/07/30/nlp-python-cn-nltk-kit/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdYVz24neSxx","executionInfo":{"status":"ok","timestamp":1617868888819,"user_tz":-480,"elapsed":3714,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"a8272c53-0617-4b5d-d62b-db824fc06bdb"},"source":["#套件\n","!pip install nltk\n","import nltk\n","\n","nltk.download(\"punkt\")\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"BIypBd2tedJB","executionInfo":{"status":"ok","timestamp":1617868550577,"user_tz":-480,"elapsed":814,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}}},"source":["#語句\n","text = \"\"\"I went to Japan. (NOT I went to the Japan.)\n","He played tennis with Ben. (NOT He played tennis with the Ben.)\n","They had breakfast at 9 o’clock. (NOT They had a breakfast at 9 o'clock.)\n","(Some words don't have an article. We don't usually use articles for countries, meals or people.)\"\"\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7rlxCxiegSv","executionInfo":{"status":"ok","timestamp":1617868564767,"user_tz":-480,"elapsed":630,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}}},"source":["#NLTK套件斷句\n","sentences = nltk.sent_tokenize(text)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdQuuQzAezRh","executionInfo":{"status":"ok","timestamp":1617868580318,"user_tz":-480,"elapsed":631,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"e70d542d-b5a9-4203-d19d-2da5ccb4cc26"},"source":["print(sentences)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['I went to Japan.', '(NOT I went to the Japan.)', 'He played tennis with Ben.', '(NOT He played tennis with the Ben.)', 'They had breakfast at 9 o’clock.', \"(NOT They had a breakfast at 9 o'clock.)\", \"(Some words don't have an article.\", \"We don't usually use articles for countries, meals or people.)\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FuG6Levue5n4","executionInfo":{"status":"ok","timestamp":1617868792408,"user_tz":-480,"elapsed":622,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"ea4cf1a8-dce4-4150-93ca-b7eb5ff9756d"},"source":["#斷詞 word_tokenize\n","tokens = [nltk.tokenize.word_tokenize(sent) for sent in sentences]\n","for token in tokens:\n","    print(token)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['I', 'went', 'to', 'Japan', '.']\n","['(', 'NOT', 'I', 'went', 'to', 'the', 'Japan', '.', ')']\n","['He', 'played', 'tennis', 'with', 'Ben', '.']\n","['(', 'NOT', 'He', 'played', 'tennis', 'with', 'the', 'Ben', '.', ')']\n","['They', 'had', 'breakfast', 'at', '9', 'o', '’', 'clock', '.']\n","['(', 'NOT', 'They', 'had', 'a', 'breakfast', 'at', '9', \"o'clock\", '.', ')']\n","['(', 'Some', 'words', 'do', \"n't\", 'have', 'an', 'article', '.']\n","['We', 'do', \"n't\", 'usually', 'use', 'articles', 'for', 'countries', ',', 'meals', 'or', 'people', '.', ')']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCkc2jEhfBS5","executionInfo":{"status":"ok","timestamp":1617868809637,"user_tz":-480,"elapsed":1027,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"c2d4ec63-32ee-4d7a-a9b9-d5c518b8fa56"},"source":["#詞性標記 pos_tag\n","pos = [nltk.pos_tag(token) for token in tokens]\n","for item in pos:\n","    print(item)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('Japan', 'NNP'), ('.', '.')]\n","[('(', '('), ('NOT', 'NNP'), ('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('Japan', 'NNP'), ('.', '.'), (')', ')')]\n","[('He', 'PRP'), ('played', 'VBD'), ('tennis', 'NN'), ('with', 'IN'), ('Ben', 'NNP'), ('.', '.')]\n","[('(', '('), ('NOT', 'NNP'), ('He', 'PRP'), ('played', 'VBD'), ('tennis', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Ben', 'NNP'), ('.', '.'), (')', ')')]\n","[('They', 'PRP'), ('had', 'VBD'), ('breakfast', 'NN'), ('at', 'IN'), ('9', 'CD'), ('o', 'JJ'), ('’', 'NN'), ('clock', 'NN'), ('.', '.')]\n","[('(', '('), ('NOT', 'NNP'), ('They', 'PRP'), ('had', 'VBD'), ('a', 'DT'), ('breakfast', 'NN'), ('at', 'IN'), ('9', 'CD'), (\"o'clock\", 'NN'), ('.', '.'), (')', ')')]\n","[('(', '('), ('Some', 'DT'), ('words', 'NNS'), ('do', 'VBP'), (\"n't\", 'RB'), ('have', 'VB'), ('an', 'DT'), ('article', 'NN'), ('.', '.')]\n","[('We', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('usually', 'RB'), ('use', 'VB'), ('articles', 'NNS'), ('for', 'IN'), ('countries', 'NNS'), (',', ','), ('meals', 'NNS'), ('or', 'CC'), ('people', 'NNS'), ('.', '.'), (')', ')')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51_kvNi_fPqk","executionInfo":{"status":"ok","timestamp":1617868830689,"user_tz":-480,"elapsed":2399,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"5a15e647-d133-4da7-c235-e88831244e6e"},"source":["#字型還原 Lemmatization\n","wordnet_pos = []\n","for p in pos:\n","    for word, tag in p:\n","        if tag.startswith('J'):\n","            wordnet_pos.append(nltk.corpus.wordnet.ADJ)\n","        elif tag.startswith('V'):\n","            wordnet_pos.append(nltk.corpus.wordnet.VERB)\n","        elif tag.startswith('N'):\n","            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n","        elif tag.startswith('R'):\n","            wordnet_pos.append(nltk.corpus.wordnet.ADV)\n","        else:\n","            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n","\n","# Lemmatizer\n","lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n","tokens = [lemmatizer.lemmatize(p[n][0], pos=wordnet_pos[n]) for p in pos for n in range(len(p))]\n","\n","for token in tokens:\n","    print(token)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["I\n","go\n","to\n","Japan\n",".\n","(\n","NOT\n","I\n","went\n","to\n","the\n","Japan\n",".\n",")\n","He\n","play\n","tennis\n","with\n","Ben\n",".\n","(\n","NOT\n","He\n","played\n","tennis\n","with\n","the\n","Ben\n",".\n",")\n","They\n","have\n","breakfast\n","at\n","9\n","o\n","’\n","clock\n",".\n","(\n","NOT\n","They\n","had\n","a\n","breakfast\n","at\n","9\n","o'clock\n",".\n",")\n","(\n","Some\n","word\n","do\n","n't\n","have\n","an\n","article\n",".\n","We\n","do\n","n't\n","usually\n","use\n","article\n","for\n","country\n",",\n","meal\n","or\n","people\n",".\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0m8L1VJfaJn","executionInfo":{"status":"ok","timestamp":1617868853861,"user_tz":-480,"elapsed":611,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"692d5446-24f5-4df1-c107-b68c051da11d"},"source":["#停用詞 nltk_stopwords\n","nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n","tokens = [token for token in tokens if token not in nltk_stopwords]\n","for token in tokens:\n","    print(token)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["I\n","go\n","Japan\n",".\n","(\n","NOT\n","I\n","went\n","Japan\n",".\n",")\n","He\n","play\n","tennis\n","Ben\n",".\n","(\n","NOT\n","He\n","played\n","tennis\n","Ben\n",".\n",")\n","They\n","breakfast\n","9\n","’\n","clock\n",".\n","(\n","NOT\n","They\n","breakfast\n","9\n","o'clock\n",".\n",")\n","(\n","Some\n","word\n","n't\n","article\n",".\n","We\n","n't\n","usually\n","use\n","article\n","country\n",",\n","meal\n","people\n",".\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGxJjMvSfgMA","executionInfo":{"status":"ok","timestamp":1617868893414,"user_tz":-480,"elapsed":637,"user":{"displayName":"rex tsou","photoUrl":"","userId":"15448100786581130255"}},"outputId":"f76feae7-77f8-41f6-d1e0-6d2ea38a62a0"},"source":["#命名實體辨識 nltk.ne_chunk\n","ne_chunked_sents = [nltk.ne_chunk(tag) for tag in pos]\n","named_entities = []\n","\n","for ne_tagged_sentence in ne_chunked_sents:\n","    for tagged_tree in ne_tagged_sentence:\n","        if hasattr(tagged_tree, 'label'):\n","            entity_name = ' '.join(c[0] for c in tagged_tree.leaves())\n","            entity_type = tagged_tree.label()\n","            named_entities.append((entity_name, entity_type))\n","            named_entities = list(set(named_entities))\n","\n","for ner in named_entities:\n","    print(ner)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["('Japan', 'GPE')\n","('Ben', 'PERSON')\n","('Ben', 'ORGANIZATION')\n"],"name":"stdout"}]}]}